report_to: [wandb]
disable_tqdm: false
wandb_project: llama3-subjective-sft #
wandb_name: llama3-8b_subjective_sft_reasoning
wandb_mode: online
wandb_log_model: "end"    
logging_first_step: true                   
logging_steps: 10

base_model: meta-llama/Meta-Llama-3-8B-Instruct        # Hugging Face model ID for LLaMA3-8B-Instruct
model_type: LlamaForCausalLM                          # Model architecture class (Llama causal language model)
tokenizer_type: AutoTokenizer                        
is_llama_derived_model: true                          # Indicates this model is LLaMA-based (for internal optimizations)

output_dir: ./output/llama3-8b-sft                    # Directory to save the fine-tuned model
num_epochs: 1                                         # Train for 1 epoch over the dataset

#change depending on how many GPUs we have - aim for roughly 256 total batch size
micro_batch_size: 8                 
gradient_accumulation_steps: 32    
deepspeed: StyleFintuning/Training/zero2_offload_master_optimizer.json
bf16: true
flash_attention: true
attn_implementation: flash_attention_2
gradient_checkpointing: true

sequence_len: 4096
#max_prompt_len: 2048


learning_rate: 0.00002                                # Initial learning rate for the optimizer (2e-5)
lr_scheduler: cosine                                  # Use a cosine decay learning rate scheduler
optimizer: adamw_torch        

eot_tokens:
  - "<|eot_id|>"
train_on_eot: turn            # include the end-of-turn token in labels per assistant turn
train_on_eos: last            # include EOS only at the very end (keeps labels clean)

excess_length_strategy: truncate   # don't silently drop long rows
pad_to_sequence_len: true

special_tokens:
  pad_token: "<|end_of_text|>"


datasets:

  - path: StyleFintuning/Data/direct_response/train.jsonl #path to trian dataset
    type: chat_template 

    #chat_template: chatml #we are using ChatML instruction format for training
    chat_template: llama3 #we are using llama3 instruction format for training llama models

    message_property_mappings:  # our mapping is consistent with ChatML
      role: role
      content: content
    
    #define how to map role keys to roles (this is may be redundant, but whatever)
    roles:
      assistant:
        - assistant
      user:
        - user
    
    roles_to_train: ["assistant"]
